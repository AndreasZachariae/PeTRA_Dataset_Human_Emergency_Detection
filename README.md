# PeTRA Dataset for Human Emergency Detection
The PeTRA dataset consists of over 18,000 single images from 200 videos as a single label, multiclass classification problem.  
It is an extensive training source for the use case of a moving mobile robot in a highly dynamic environment with multiple people.  

There are three different use cases for this dataset which correspond to the transport modes of the PeTRA robot. The first transport mode is with self-walking patients only, this includes patients with rollator who can be partially obscured. This set only consists of the binary output classes "Normal" and "Emergency". The second mode is for transportation with wheelchair only and the third mode is a combination of both datasets for transports where both scenarios occur and to train a single model as comparison to the specific models trained on the separate datasets. All of the scenes are partially static and dynamic in which the robot moves in front of the person. The use-case requires a multi-person detection with tracking over frames, therefor the number of people simultaneously visible in the scene ranges from 1 to 5. There are 20 unique persons with 50 \% male and female distribution. The locations differ from scenes in the laboratory with and without daylight as well as scenes from hospital floors with only artificial lightning, see Fig. \ref{fig:dataset_example_images} for examples. It was recorded with two different cameras. The first is a Roboception rc\textunderscore visard 160 color which is a stereo camera with 160 mm baseline and has a color image resolution of 1280x960 at 25 Hz and a depth image resolution of 640x480 with a range from 0.5 m to infinity. The second camera is a RealSense D415 which is also a stereo camera with 55 mm baseline, color image resolution of 1920x1080 at 30 Hz and depth image resolution of 640x480 with a range from 0.5 m to 3 m. 
